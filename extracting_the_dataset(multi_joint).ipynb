{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive to access persistent storage\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create dataset folder in Drive for storing the downloaded ZIP\n",
        "import os\n",
        "dataset_dir = '/content/drive/MyDrive/multi_joint_mi_dataset'\n",
        "os.makedirs(dataset_dir, exist_ok=True)\n",
        "\n",
        "print(f\"Dataset folder created at: {dataset_dir}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEkrNBluHuUb",
        "outputId": "6e80b75f-20bc-4d15-af46-852f263640cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Dataset folder created at: /content/drive/MyDrive/multi_joint_mi_dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the Multi-Joint Upper Limb MI Dataset (2025)\n",
        "# Direct download link: https://figshare.com/ndownloader/articles/24123303/versions/3\n",
        "\n",
        "# Install required packages\n",
        "!pip install requests tqdm -q\n",
        "\n",
        "import requests\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Direct download URL\n",
        "zip_url = \"https://figshare.com/ndownloader/articles/24123303/versions/3\"\n",
        "zip_path = os.path.join(dataset_dir, \"multi_joint_mi_dataset.zip\")\n",
        "\n",
        "# Remove any existing corrupted file (< 1MB)\n",
        "if os.path.exists(zip_path):\n",
        "    file_size = os.path.getsize(zip_path)\n",
        "    if file_size < 1024 * 1024:  # Less than 1MB\n",
        "        print(f\"Removing corrupted file ({file_size} bytes)...\")\n",
        "        os.remove(zip_path)\n",
        "\n",
        "print(f\"Downloading dataset to: {zip_path}\")\n",
        "print(f\"File size: ~17 GB (this may take a while...)\")\n",
        "print(\"Starting download...\\n\")\n",
        "\n",
        "# Download with progress bar\n",
        "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}\n",
        "\n",
        "try:\n",
        "    response = requests.get(zip_url, headers=headers, stream=True, allow_redirects=True, timeout=60)\n",
        "    response.raise_for_status()  # Raise error for bad status codes\n",
        "\n",
        "    # Get file size from headers\n",
        "    total_size = int(response.headers.get('content-length', 0))\n",
        "\n",
        "    # Download with progress bar\n",
        "    with open(zip_path, 'wb') as f:\n",
        "        with tqdm(total=total_size, unit='B', unit_scale=True, unit_divisor=1024, desc=\"Downloading\") as pbar:\n",
        "            for chunk in response.iter_content(chunk_size=8192):\n",
        "                if chunk:\n",
        "                    f.write(chunk)\n",
        "                    pbar.update(len(chunk))\n",
        "\n",
        "    # Verify download\n",
        "    final_size = os.path.getsize(zip_path) / (1024**3)\n",
        "    print(f\"\\n✓ Download complete!\")\n",
        "    print(f\"File size: {final_size:.2f} GB\")\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"\\n✗ Download failed: {str(e)}\")\n",
        "    print(\"\\nTroubleshooting:\")\n",
        "    print(\"1. Check internet connection\")\n",
        "    print(\"2. Verify Drive mount is active\")\n",
        "    print(\"3. Ensure sufficient storage space (~20 GB free)\")\n",
        "    print(\"4. Try running this cell again\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isrAh8YWHxj2",
        "outputId": "c2d278e6-a62e-4c73-d9c7-e38e43f1e1a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading dataset to: /content/drive/MyDrive/multi_joint_mi_dataset/multi_joint_mi_dataset.zip\n",
            "File size: ~17 GB (this may take a while...)\n",
            "Starting download...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: 100%|██████████| 16.9G/16.9G [08:11<00:00, 36.9MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Download complete!\n",
            "File size: 16.87 GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset_dir = multi_joint_mi_dataset\n",
        "\n",
        "# Install required packages\n",
        "!pip install mne scipy -q\n",
        "\n",
        "# Unzip dataset (extract all subjects)\n",
        "import zipfile\n",
        "import os\n",
        "#address be file zip = multi_joint_mi_dataset (data_dir)/multi_joint_mi_dataset.zip\n",
        "zip_path = os.path.join(dataset_dir, \"multi_joint_mi_dataset.zip\")\n",
        "#address be file extract shode = multi_joint_mi_dataset (data_dir) /extracted\n",
        "extract_dir = os.path.join(dataset_dir, \"extracted\")\n",
        "#agar folder baraye extract vojood nadasht create kon\n",
        "os.makedirs(extract_dir, exist_ok=True)\n",
        "\n",
        "print(\"Extracting dataset...\")\n",
        "print(\"This may take a few minutes for ~17 GB...\")\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    # Extract all files\n",
        "    zip_ref.extractall(extract_dir)\n",
        "\n",
        "print(f\"✓ Extraction complete!\")\n",
        "print(f\"Files extracted to: {extract_dir}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_zy4OxzK64A",
        "outputId": "9562d7e0-0fe2-441c-94ad-4c646fb0d013"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting dataset...\n",
            "This may take a few minutes for ~17 GB...\n",
            "✓ Extraction complete!\n",
            "Files extracted to: /content/drive/MyDrive/multi_joint_mi_dataset/extracted\n",
            "\n",
            "Found 0 subject folders:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1rM83lD0UoIF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}