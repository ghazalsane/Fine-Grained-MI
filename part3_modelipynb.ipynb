{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wu7mSm-1QsB8",
        "outputId": "e4bc35e9-df4f-4acd-e3f0-48b8747499ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "✓ Google Drive mounted!\n",
            "Project root (extract_dir): /content/drive/MyDrive/multi_joint_mi_dataset/extracted\n",
            "✓ Required folders found!\n",
            " - aligned_dir: /content/drive/MyDrive/multi_joint_mi_dataset/extracted/aligned_datasets\n",
            "Found 18 aligned files.\n",
            "  • subject10_aligned.npz\n",
            "  • subject11_aligned.npz\n",
            "  • subject12_aligned.npz\n",
            "  • subject13_aligned.npz\n",
            "  • subject14_aligned.npz\n",
            "  • subject15_aligned.npz\n",
            "  • subject16_aligned.npz\n",
            "  • subject17_aligned.npz\n",
            "  • subject18_aligned.npz\n",
            "  • subject1_aligned.npz\n",
            "  • subject2_aligned.npz\n",
            "  • subject3_aligned.npz\n",
            "  • subject4_aligned.npz\n",
            "  • subject5_aligned.npz\n",
            "  • subject6_aligned.npz\n",
            "  • subject7_aligned.npz\n",
            "  • subject8_aligned.npz\n",
            "  • subject9_aligned.npz\n",
            "\n",
            "✓ Ready to load aligned subjects!\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# 1) Connect Google Drive\n",
        "# ==========================================\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "print(\"✓ Google Drive mounted!\")\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "# 2) Set up project paths\n",
        "# ==========================================\n",
        "import os\n",
        "\n",
        "# Path to your FineMI / extracted data root\n",
        "# ⚠️ Update ONLY IF your folder name is different\n",
        "extract_dir = \"/content/drive/MyDrive/multi_joint_mi_dataset/extracted\"\n",
        "\n",
        "print(\"Project root (extract_dir):\", extract_dir)\n",
        "\n",
        "# Common subfolders\n",
        "aligned_dir = os.path.join(extract_dir, \"aligned_datasets\")\n",
        "raw_eeg_dir = os.path.join(extract_dir, \"FineMI/FineMI\")  # optional, if needed\n",
        "\n",
        "# ==========================================\n",
        "# 3) Check existence of required folders\n",
        "# ==========================================\n",
        "if not os.path.exists(extract_dir):\n",
        "    raise FileNotFoundError(f\"extract_dir not found: {extract_dir}\")\n",
        "\n",
        "if not os.path.exists(aligned_dir):\n",
        "    raise FileNotFoundError(\n",
        "        f\"aligned_datasets folder not found at: {aligned_dir}\\n\"\n",
        "        f\"Make sure your previous notebook saved files correctly.\"\n",
        "    )\n",
        "\n",
        "print(\"✓ Required folders found!\")\n",
        "print(\" - aligned_dir:\", aligned_dir)\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "# 4) List what aligned files exist\n",
        "# ==========================================\n",
        "import glob\n",
        "\n",
        "aligned_files = sorted(glob.glob(os.path.join(aligned_dir, \"subject*_aligned.npz\")))\n",
        "\n",
        "print(f\"Found {len(aligned_files)} aligned files.\")\n",
        "for f in aligned_files:\n",
        "    print(\"  •\", os.path.basename(f))\n",
        "\n",
        "if len(aligned_files) == 0:\n",
        "    print(\"⚠ No aligned dataset files found. Did the preprocessing notebook run?\")\n",
        "else:\n",
        "    print(\"\\n✓ Ready to load aligned subjects!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load all aligned datasets and prepare for training\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "from collections import defaultdict\n",
        "\n",
        "# Find all aligned files\n",
        "aligned_dir = os.path.join(extract_dir, \"aligned_datasets\")\n",
        "aligned_files = sorted(glob.glob(os.path.join(aligned_dir, \"subject*_aligned.npz\")))\n",
        "\n",
        "print(f\"Found {len(aligned_files)} aligned dataset files\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "\n",
        "MATCH_RATE_THRESHOLD = 80.0  #Minimum % match rate you accept.lower than this will be excluded\n",
        "bad_subjects = set()          #Empty set to remember the names of subjects you exclude (e.g. \"subject10\")\n",
        "#create a collection of unique, unordered elements (it's like implementing a finite set)\n",
        "all_eeg_data = []   #List that will collect eeg_data arrays from each included subject.\n",
        "all_fnirs_data = [] #List that will collect fnirs_data arrays from each included subject.\n",
        "all_labels = []     #List that will collect label arrays from each included subject.\n",
        "subject_ids = []    #Will store a subject ID for each trial, useful later for subject-wise splits.\n",
        "alignment_stats = []#Will store dictionaries with info about each subject’s alignment quality.\n",
        "\n",
        "for file_path in aligned_files:#Iterates through each file path, e.g. \"../subject2_aligned.npz\".\n",
        "    subject_name = os.path.basename(file_path).replace(\"_aligned.npz\", \"\")\n",
        "#os.path.basename(file_path) → gets just the file name, e.g. \"subject2_aligned.npz\".\n",
        "#.replace(\"_aligned.npz\", \"\") → removes this suffix → you get \"subject2\".\n",
        "\n",
        "    subject_num = int(subject_name.replace(\"subject\", \"\"))\n",
        " #.replace(\"subject\", \"\") → from \"subject2\" to \"2\".\n",
        " #int(...) → converts \"2\" to integer 2. Because we are extracting the subject ID from the name, we should convert.\n",
        "\n",
        "\n",
        "    data = np.load(file_path, allow_pickle=True)#Loads the .npz file into a NumPy NpzFile object.\n",
        "\n",
        "    eeg_data = data['eeg_data']\n",
        "    #Loads EEG array for this subject, likely shaped (n_trials, n_channels_eeg, n_time_eeg).\n",
        "    fnirs_data = data['fnirs_data']\n",
        "    #Loads fNIRS array for this subject, (n_trials, n_channels_fnirs, n_time_fnirs)\n",
        "    labels = data['labels']\n",
        "    #Loads label vector, shape (n_trials,), values in 0..7\n",
        "    align_info = data['alignment_info'].item() if hasattr(data['alignment_info'], 'item') else data['alignment_info']\n",
        "    #data['alignment_info'] is often stored as a zero-dimensional object array (like array(dict_obj, dtype=object)), so:\n",
        "    #f it has .item(), we call .item() to extract the actual Python dict.\n",
        "    #Otherwise we use it as-is.\n",
        "  #Result: align_info is a Python dict with keys like 'raw_match_rate', 'best_shift', etc.\n",
        "    raw_match_rate = align_info.get('raw_match_rate', 100.0)\n",
        "\n",
        "\n",
        "    #Tries to read 'raw_match_rate' key from the dict. If not found, defaults to 100.0!\n",
        "\n",
        "    # Check alignment quality. CHECKING IF THE SUBJECT IS GOOD ENOUGH\n",
        "    if raw_match_rate < MATCH_RATE_THRESHOLD:\n",
        "        bad_subjects.add(subject_name)    #Add \"subjectX\" to the excluded set.\n",
        "        print(f\"⚠ {subject_name}: EXCLUDED (raw_match_rate={raw_match_rate:.1f}% < {MATCH_RATE_THRESHOLD}%)\")\n",
        "        continue      #Skip the rest of the loop body (do not add this subject’s data to the global lists); move on to the next file.\n",
        "\n",
        "    # Include this subject. THIS IS EXCECUTED ONLY IF THE SUBJECT PASSED THE ALIGNMENT THRESHOLD!\n",
        "    all_eeg_data.append(eeg_data)     #Add this subject’s EEG trials array to the list.\n",
        "    all_fnirs_data.append(fnirs_data) #same\n",
        "    all_labels.append(labels)         #same\n",
        "    subject_ids.extend([subject_num] * len(labels))\n",
        "    #Creates a list like [2, 2, 2, ..., 2] (one per trial for subject 2) and extends subject_ids with it.\n",
        "    #After the loop, subject_ids has length = total number of trials from all good subjects. BE ANDAZEYE TEDADE TRIAL HA ID DARIM.\n",
        "\n",
        "\n",
        "\n",
        "    #Appends a dict with:\n",
        "    #'subject': \"subject2\", etc.\n",
        "    #'n_trials': how many trials this subject contributed.\n",
        "    #'best_shift': the time shift that gave best alignment (if stored).\n",
        "    #'raw_match_rate'\n",
        "\n",
        "    #alignment_stats becomes a list of “rows” we can later convert to a DataFrame or print.\n",
        "    alignment_stats.append({\n",
        "        'subject': subject_name,\n",
        "        'n_trials': len(labels),\n",
        "        'best_shift': align_info.get('best_shift', 0),\n",
        "        'raw_match_rate': raw_match_rate\n",
        "    })\n",
        "\n",
        "    print(f\"✓ {subject_name}: {len(labels)} trials, shift={align_info.get('best_shift', 0)}, match_rate={raw_match_rate:.1f}%\")\n",
        "\n",
        "###############################################################################\n",
        "if bad_subjects:          #IF THE SET IS NOT EMPTY AND SOME SUBJECTS WERE EXCLUDED, Loop through sorted bad subject names and print each.\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"Excluded Subjects (raw_match_rate < 80%)\")\n",
        "    print(f\"{'='*60}\")\n",
        "    for subj in sorted(bad_subjects): #Loop through sorted bad subject names and print each.\n",
        "        print(f\"  - {subj}\")\n",
        "    print(f\"\\nTotal excluded: {len(bad_subjects)} subjects\")  #Print how many total were excluded.\n",
        "else:\n",
        "    print(f\"\\n✓ No subjects excluded (all have raw_match_rate >= {MATCH_RATE_THRESHOLD}%)\")\n",
        "#################################################################################\n",
        "\n",
        "\n",
        "# Concatenate all included subjects\n",
        "if len(all_eeg_data) == 0:        #Before concatenating, check if any subject made it through.\n",
        "    raise ValueError(\"No subjects passed the alignment quality threshold! Check your data.\")\n",
        "\n",
        "eeg_all = np.concatenate(all_eeg_data, axis=0)    #concatenation along axis 0 (so we'll have total_trials,channel,timepoint)\n",
        "fnirs_all = np.concatenate(all_fnirs_data, axis=0)  #same\n",
        "labels_all = np.concatenate(all_labels, axis=0)      #stacking all label vectors into one big vector (total_trials,).\n",
        "subject_ids_all = np.array(subject_ids)\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"Dataset Summary\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"Included subjects: {len(all_eeg_data)}\")\n",
        "print(f\"Excluded subjects: {len(bad_subjects)}\")\n",
        "print(f\"Total trials: {len(labels_all)}\")\n",
        "print(f\"EEG shape: {eeg_all.shape}\")\n",
        "print(f\"fNIRS shape: {fnirs_all.shape}\")\n",
        "print(f\"Labels shape: {labels_all.shape}\")\n",
        "print(f\"Label distribution: {np.bincount(labels_all)}\")\n",
        "print(f\"Unique subjects: {len(np.unique(subject_ids_all))}\")\n",
        "\n",
        "# Store in variables for next steps\n",
        "print(f\"\\n✓ Data loaded and ready for model training!\")\n",
        "print(f\"\\nAvailable variables:\")\n",
        "print(f\"  - eeg_all: EEG data ({eeg_all.shape})\")\n",
        "print(f\"  - fnirs_all: fNIRS data ({fnirs_all.shape})\")\n",
        "print(f\"  - labels_all: Labels ({labels_all.shape})\")\n",
        "print(f\"  - subject_ids_all: Subject IDs for each trial\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P02gjXNtQt8L",
        "outputId": "461ab479-99d0-4a11-93bb-2b0231729fc1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 18 aligned dataset files\n",
            "============================================================\n",
            "⚠ subject10: EXCLUDED (raw_match_rate=42.8% < 80.0%)\n",
            "✓ subject11: 280 trials, shift=8, match_rate=87.5%\n",
            "✓ subject12: 320 trials, shift=1, match_rate=100.0%\n",
            "✓ subject13: 320 trials, shift=0, match_rate=100.0%\n",
            "⚠ subject14: EXCLUDED (raw_match_rate=66.6% < 80.0%)\n",
            "✓ subject15: 320 trials, shift=0, match_rate=100.0%\n",
            "✓ subject16: 320 trials, shift=0, match_rate=100.0%\n",
            "✓ subject17: 320 trials, shift=0, match_rate=100.0%\n",
            "✓ subject18: 320 trials, shift=0, match_rate=100.0%\n",
            "✓ subject1: 360 trials, shift=0, match_rate=100.0%\n",
            "✓ subject2: 320 trials, shift=0, match_rate=100.0%\n",
            "✓ subject3: 320 trials, shift=0, match_rate=100.0%\n",
            "✓ subject4: 320 trials, shift=0, match_rate=100.0%\n",
            "✓ subject5: 321 trials, shift=0, match_rate=100.0%\n",
            "✓ subject6: 320 trials, shift=0, match_rate=100.0%\n",
            "✓ subject7: 320 trials, shift=0, match_rate=100.0%\n",
            "✓ subject8: 319 trials, shift=0, match_rate=99.7%\n",
            "✓ subject9: 320 trials, shift=0, match_rate=100.0%\n",
            "\n",
            "============================================================\n",
            "Excluded Subjects (raw_match_rate < 80%)\n",
            "============================================================\n",
            "  - subject10\n",
            "  - subject14\n",
            "\n",
            "Total excluded: 2 subjects\n",
            "\n",
            "============================================================\n",
            "Dataset Summary\n",
            "============================================================\n",
            "Included subjects: 16\n",
            "Excluded subjects: 2\n",
            "Total trials: 5120\n",
            "EEG shape: (5120, 68, 1126)\n",
            "fNIRS shape: (5120, 24, 40)\n",
            "Labels shape: (5120,)\n",
            "Label distribution: [640 640 640 640 640 640 639 641]\n",
            "Unique subjects: 16\n",
            "\n",
            "✓ Data loaded and ready for model training!\n",
            "\n",
            "Available variables:\n",
            "  - eeg_all: EEG data ((5120, 68, 1126))\n",
            "  - fnirs_all: fNIRS data ((5120, 24, 40))\n",
            "  - labels_all: Labels ((5120,))\n",
            "  - subject_ids_all: Subject IDs for each trial\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "\n",
        "print(\"===== PER-FILE SANITY CHECKS =====\")\n",
        "\n",
        "aligned_dir = os.path.join(extract_dir, \"aligned_datasets\")\n",
        "aligned_files = sorted(glob.glob(os.path.join(aligned_dir, \"subject*_aligned.npz\")))\n",
        "\n",
        "if not aligned_files:\n",
        "    raise FileNotFoundError(f\"No aligned files found in {aligned_dir}\")\n",
        "\n",
        "print(f\"Found {len(aligned_files)} aligned files\\n\")\n",
        "\n",
        "per_file_ok = True\n",
        "\n",
        "for file_path in aligned_files:\n",
        "    subject_name = os.path.basename(file_path).replace(\"_aligned.npz\", \"\")\n",
        "    data = np.load(file_path, allow_pickle=True)\n",
        "\n",
        "    eeg_data = data['eeg_data']\n",
        "    fnirs_data = data['fnirs_data']\n",
        "    labels = data['labels']\n",
        "\n",
        "    # Basic shapes\n",
        "    print(f\"--- {subject_name} ---\")\n",
        "    print(\"  EEG shape   :\", eeg_data.shape)\n",
        "    print(\"  fNIRS shape :\", fnirs_data.shape)\n",
        "    print(\"  Labels shape:\", labels.shape)\n",
        "\n",
        "    # Check trial count consistency\n",
        "    n_eeg_trials   = eeg_data.shape[0]\n",
        "    n_fnirs_trials = fnirs_data.shape[0]\n",
        "    n_label_trials = labels.shape[0]\n",
        "\n",
        "    if not (n_eeg_trials == n_fnirs_trials == n_label_trials):\n",
        "        print(\"  ⚠ MISMATCH in trial counts!\",\n",
        "              f\"(EEG={n_eeg_trials}, fNIRS={n_fnirs_trials}, labels={n_label_trials})\")\n",
        "        per_file_ok = False\n",
        "\n",
        "    # Quick label sanity check\n",
        "    unique_labels = np.unique(labels)\n",
        "    print(\"  Unique labels:\", unique_labels)\n",
        "\n",
        "    # NaN / inf checks (per subject)\n",
        "    has_nan_eeg   = np.isnan(eeg_data).any()\n",
        "    has_nan_fnirs = np.isnan(fnirs_data).any()\n",
        "    has_nan_labels = np.isnan(labels).any()\n",
        "\n",
        "    has_inf_eeg   = np.isinf(eeg_data).any()\n",
        "    has_inf_fnirs = np.isinf(fnirs_data).any()\n",
        "    has_inf_labels = np.isinf(labels).any()\n",
        "\n",
        "    if has_nan_eeg or has_nan_fnirs or has_nan_labels:\n",
        "        print(\"  ⚠ NaNs detected in this subject \"\n",
        "              f\"(EEG={has_nan_eeg}, fNIRS={has_nan_fnirs}, labels={has_nan_labels})\")\n",
        "        per_file_ok = False\n",
        "\n",
        "    if has_inf_eeg or has_inf_fnirs or has_inf_labels:\n",
        "        print(\"  ⚠ Infs detected in this subject \"\n",
        "              f\"(EEG={has_inf_eeg}, fNIRS={has_inf_fnirs}, labels={has_inf_labels})\")\n",
        "        per_file_ok = False\n",
        "\n",
        "    print()\n",
        "\n",
        "if per_file_ok:\n",
        "    print(\"✓ All per-file checks passed (shapes & basic sanity look OK)\\n\")\n",
        "else:\n",
        "    print(\"⚠ Some issues detected above — fix before training!\\n\")\n",
        "\n",
        "\n",
        "# ===== GLOBAL / CONCATENATED ARRAY CHECKS =====\n",
        "print(\"===== GLOBAL CONCATENATED ARRAY CHECKS =====\")\n",
        "\n",
        "try:\n",
        "    # These should already exist from your previous loading code\n",
        "    print(\"eeg_all shape        :\", eeg_all.shape)\n",
        "    print(\"fnirs_all shape      :\", fnirs_all.shape)\n",
        "    print(\"labels_all shape     :\", labels_all.shape)\n",
        "    print(\"subject_ids_all shape:\", subject_ids_all.shape)\n",
        "\n",
        "    # Dimensionality expectations\n",
        "    if eeg_all.ndim != 3:\n",
        "        print(\"  ⚠ eeg_all is not 3D (expected (trials, channels, time))\")\n",
        "    if fnirs_all.ndim != 3:\n",
        "        print(\"  ⚠ fnirs_all is not 3D (expected (trials, channels, time))\")\n",
        "    if labels_all.ndim != 1:\n",
        "        print(\"  ⚠ labels_all is not 1D\")\n",
        "    if subject_ids_all.ndim != 1:\n",
        "        print(\"  ⚠ subject_ids_all is not 1D\")\n",
        "\n",
        "    # Trial counts consistency\n",
        "    n_trials_eeg   = eeg_all.shape[0]\n",
        "    n_trials_fnirs = fnirs_all.shape[0]\n",
        "    n_trials_labels = labels_all.shape[0]\n",
        "    n_trials_ids    = subject_ids_all.shape[0]\n",
        "\n",
        "    print(\"\\nTrial counts:\")\n",
        "    print(\"  EEG trials       :\", n_trials_eeg)\n",
        "    print(\"  fNIRS trials     :\", n_trials_fnirs)\n",
        "    print(\"  Label entries    :\", n_trials_labels)\n",
        "    print(\"  Subject ID entries:\", n_trials_ids)\n",
        "\n",
        "    if len({n_trials_eeg, n_trials_fnirs, n_trials_labels, n_trials_ids}) != 1:\n",
        "        print(\"  ⚠ MISMATCH in trial counts across global arrays!\")\n",
        "    else:\n",
        "        print(\"  ✓ Trial counts consistent across all arrays\")\n",
        "\n",
        "    # Label distribution\n",
        "    print(\"\\nLabel distribution (global):\")\n",
        "    print(\"  np.bincount(labels_all) =\", np.bincount(labels_all))\n",
        "\n",
        "    # Global NaN / inf check\n",
        "    print(\"\\nNaN / Inf checks (global):\")\n",
        "    print(\"  NaNs in EEG   :\", np.isnan(eeg_all).any())\n",
        "    print(\"  NaNs in fNIRS :\", np.isnan(fnirs_all).any())\n",
        "    print(\"  NaNs in labels:\", np.isnan(labels_all).any())\n",
        "    print(\"  Infs in EEG   :\", np.isinf(eeg_all).any())\n",
        "    print(\"  Infs in fNIRS :\", np.isinf(fnirs_all).any())\n",
        "    print(\"  Infs in labels:\", np.isinf(labels_all).any())\n",
        "\n",
        "except NameError as e:\n",
        "    print(\"⚠ Some global arrays (eeg_all, fnirs_all, labels_all, subject_ids_all) \"\n",
        "          \"are not defined yet.\")\n",
        "    print(\"  Error:\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcFopAyhRC8r",
        "outputId": "6fe6c31d-06c7-4df3-8130-8f16fcadae1d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== PER-FILE SANITY CHECKS =====\n",
            "Found 18 aligned files\n",
            "\n",
            "--- subject10 ---\n",
            "  EEG shape   : (137, 68, 1126)\n",
            "  fNIRS shape : (137, 24, 40)\n",
            "  Labels shape: (137,)\n",
            "  Unique labels: [0 1 2 3 4 5 6 7]\n",
            "\n",
            "--- subject11 ---\n",
            "  EEG shape   : (280, 68, 1126)\n",
            "  fNIRS shape : (280, 24, 40)\n",
            "  Labels shape: (280,)\n",
            "  Unique labels: [0 1 2 3 4 5 6 7]\n",
            "\n",
            "--- subject12 ---\n",
            "  EEG shape   : (320, 68, 1126)\n",
            "  fNIRS shape : (320, 24, 40)\n",
            "  Labels shape: (320,)\n",
            "  Unique labels: [0 1 2 3 4 5 6 7]\n",
            "\n",
            "--- subject13 ---\n",
            "  EEG shape   : (320, 68, 1126)\n",
            "  fNIRS shape : (320, 24, 40)\n",
            "  Labels shape: (320,)\n",
            "  Unique labels: [0 1 2 3 4 5 6 7]\n",
            "\n",
            "--- subject14 ---\n",
            "  EEG shape   : (213, 68, 1126)\n",
            "  fNIRS shape : (213, 24, 40)\n",
            "  Labels shape: (213,)\n",
            "  Unique labels: [0 1 2 3 4 5 6 7]\n",
            "\n",
            "--- subject15 ---\n",
            "  EEG shape   : (320, 68, 1126)\n",
            "  fNIRS shape : (320, 24, 40)\n",
            "  Labels shape: (320,)\n",
            "  Unique labels: [0 1 2 3 4 5 6 7]\n",
            "\n",
            "--- subject16 ---\n",
            "  EEG shape   : (320, 68, 1126)\n",
            "  fNIRS shape : (320, 24, 40)\n",
            "  Labels shape: (320,)\n",
            "  Unique labels: [0 1 2 3 4 5 6 7]\n",
            "\n",
            "--- subject17 ---\n",
            "  EEG shape   : (320, 68, 1126)\n",
            "  fNIRS shape : (320, 24, 40)\n",
            "  Labels shape: (320,)\n",
            "  Unique labels: [0 1 2 3 4 5 6 7]\n",
            "\n",
            "--- subject18 ---\n",
            "  EEG shape   : (320, 68, 1126)\n",
            "  fNIRS shape : (320, 24, 40)\n",
            "  Labels shape: (320,)\n",
            "  Unique labels: [0 1 2 3 4 5 6 7]\n",
            "\n",
            "--- subject1 ---\n",
            "  EEG shape   : (360, 68, 1126)\n",
            "  fNIRS shape : (360, 24, 40)\n",
            "  Labels shape: (360,)\n",
            "  Unique labels: [0 1 2 3 4 5 6 7]\n",
            "\n",
            "--- subject2 ---\n",
            "  EEG shape   : (320, 68, 1126)\n",
            "  fNIRS shape : (320, 24, 40)\n",
            "  Labels shape: (320,)\n",
            "  Unique labels: [0 1 2 3 4 5 6 7]\n",
            "\n",
            "--- subject3 ---\n",
            "  EEG shape   : (320, 68, 1126)\n",
            "  fNIRS shape : (320, 24, 40)\n",
            "  Labels shape: (320,)\n",
            "  Unique labels: [0 1 2 3 4 5 6 7]\n",
            "\n",
            "--- subject4 ---\n",
            "  EEG shape   : (320, 68, 1126)\n",
            "  fNIRS shape : (320, 24, 40)\n",
            "  Labels shape: (320,)\n",
            "  Unique labels: [0 1 2 3 4 5 6 7]\n",
            "\n",
            "--- subject5 ---\n",
            "  EEG shape   : (321, 68, 1126)\n",
            "  fNIRS shape : (321, 24, 40)\n",
            "  Labels shape: (321,)\n",
            "  Unique labels: [0 1 2 3 4 5 6 7]\n",
            "\n",
            "--- subject6 ---\n",
            "  EEG shape   : (320, 68, 1126)\n",
            "  fNIRS shape : (320, 24, 40)\n",
            "  Labels shape: (320,)\n",
            "  Unique labels: [0 1 2 3 4 5 6 7]\n",
            "\n",
            "--- subject7 ---\n",
            "  EEG shape   : (320, 68, 1126)\n",
            "  fNIRS shape : (320, 24, 40)\n",
            "  Labels shape: (320,)\n",
            "  Unique labels: [0 1 2 3 4 5 6 7]\n",
            "\n",
            "--- subject8 ---\n",
            "  EEG shape   : (319, 68, 1126)\n",
            "  fNIRS shape : (319, 24, 40)\n",
            "  Labels shape: (319,)\n",
            "  Unique labels: [0 1 2 3 4 5 6 7]\n",
            "\n",
            "--- subject9 ---\n",
            "  EEG shape   : (320, 68, 1126)\n",
            "  fNIRS shape : (320, 24, 40)\n",
            "  Labels shape: (320,)\n",
            "  Unique labels: [0 1 2 3 4 5 6 7]\n",
            "\n",
            "✓ All per-file checks passed (shapes & basic sanity look OK)\n",
            "\n",
            "===== GLOBAL CONCATENATED ARRAY CHECKS =====\n",
            "eeg_all shape        : (5120, 68, 1126)\n",
            "fnirs_all shape      : (5120, 24, 40)\n",
            "labels_all shape     : (5120,)\n",
            "subject_ids_all shape: (5120,)\n",
            "\n",
            "Trial counts:\n",
            "  EEG trials       : 5120\n",
            "  fNIRS trials     : 5120\n",
            "  Label entries    : 5120\n",
            "  Subject ID entries: 5120\n",
            "  ✓ Trial counts consistent across all arrays\n",
            "\n",
            "Label distribution (global):\n",
            "  np.bincount(labels_all) = [640 640 640 640 640 640 639 641]\n",
            "\n",
            "NaN / Inf checks (global):\n",
            "  NaNs in EEG   : False\n",
            "  NaNs in fNIRS : False\n",
            "  NaNs in labels: False\n",
            "  Infs in EEG   : False\n",
            "  Infs in fNIRS : False\n",
            "  Infs in labels: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install PyTorch if needed\n",
        "!pip install torch torchvision -q\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_9j_-QSRGw_",
        "outputId": "9a40e331-1305-4948-dcd5-fbcf7f2502ac"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.9.0+cu126\n",
            "CUDA available: True\n",
            "CUDA device: NVIDIA A100-SXM4-80GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, random\n",
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"  # or \":16:8\"\n",
        "\n",
        "SEED = 42\n",
        "\n",
        "def seed_everything(seed=42, deterministic=True):\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    if deterministic:\n",
        "        # CuDNN / CUDA determinism\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "\n",
        "        # Use deterministic algorithms when available\n",
        "        torch.use_deterministic_algorithms(False)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "\n",
        "        # Required for some CUDA deterministic behavior (esp. matmul)\n",
        "        os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
        "\n",
        "seed_everything(SEED, deterministic=True)\n",
        "print(\"Seeded & deterministic mode ON\")\n",
        "\n",
        "\n",
        "def seed_worker(worker_id):\n",
        "    worker_seed = SEED + worker_id\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)\n",
        "    torch.manual_seed(worker_seed)\n",
        "\n",
        "g = torch.Generator()\n",
        "g.manual_seed(SEED)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpZ25aoHQt_O",
        "outputId": "fb0af141-c0e4-4269-f7ee-b66bfba9d1da"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seeded & deterministic mode ON\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7c60399ff5d0>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
        "\n",
        "\n",
        "# ===========================================================\n",
        "# CONFIG\n",
        "# ===========================================================\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", DEVICE)\n",
        "\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "BINARY_CLASSES = [0, 6]\n",
        "N_FOLDS = 5\n",
        "BATCH_SIZE = 32\n",
        "BASE_CHANNELS = 64     #Width of the ConvBranch (number of filters)\n",
        "\n",
        "# Global teacher pretrain (on all subjects except target subject)\n",
        "EPOCHS_GLOBAL_PRETRAIN = 20\n",
        "LR_GLOBAL = 3e-4    #Learning rate for global teacher pretraining\n",
        "\n",
        "# Teacher fold fine-tune\n",
        "EPOCHS_TEACHER_FT = 15 #Max epochs to adapt the teacher to the target subject fold. Shouldn't be too long, can overfit that subject’s train split.\n",
        "LR_TEACHER_FT = 1e-4\n",
        "\n",
        "# Student training\n",
        "EPOCHS_STUDENT = 20   #Max training epochs for baseline and KD students.\n",
        "LR_STUDENT = 3e-4\n",
        "\n",
        "WEIGHT_DECAY = 1e-4\n",
        "PATIENCE = 6      #Early stopping patience on validation accuracy\n",
        "\n",
        "# Distillation (base)\n",
        "DISTILL_ALPHA = 0.4   #Weights CE vs KD in your combined loss. Higher alpha (e.g., 0.7) → more “trust labels”, less teacher influence (safer)\n",
        "DISTILL_T = 3.0\n",
        "#Temperature softens teacher probabilities (and student logits in KL)\n",
        "#Higher T → softer probabilities → KD carries more “dark knowledge” (class similarity), can help.\n",
        "\n",
        "# Train students with plain CE first, then turn on KD. early student logits are garbage\n",
        "WARMUP_EPOCHS = 6\n",
        "\n",
        "# ---- UPGRADE 2: sample-level teacher confidence gating ----\n",
        "KD_CONF_THRESH = 0.70  # apply KD only if teacher max prob >= this\n",
        "#For every single trial, the teacher outputs two numbers (logits), one per class. You convert them to probabilities. max of these will be confidence\n",
        "#example:If the teacher says [0.95, 0.05] → confidence = 0.95 (very confident)\n",
        "\n",
        "\n",
        "\n",
        "# Optional: validation gating (model-level)\n",
        "USE_VAL_GATE = True #Turns on “choose KD model only if it’s actually better on validation”\n",
        "VAL_GATE_MARGIN = 0.02  #KD must beat baseline val accuracy by at least +2% to be selected.\n",
        "#For each fold, you train two separate students:\n",
        "#Baseline student (trained with CE only)\n",
        "#KD student (trained with CE + distillation)\n",
        "#Then you evaluate both on the validation set (the held-out 20% from the training fold).\n",
        "#If the KD student is clearly better on validation, you use the KD student for the final test set.\n",
        "#If not, you ignore KD and use the baseline student.\n",
        "\n",
        "# ===========================================================\n",
        "# DATASET\n",
        "# ===========================================================\n",
        "class MI_Dataset(Dataset):\n",
        "    def __init__(self, eeg, fnirs, y):\n",
        "      #we have these three\n",
        "      #Converts inputs to NumPy arrays\n",
        "      #Expected shapes:eeg is typically (N, C_eeg, T_eeg), fnirs is typically (N, C_fnirs, T_fnirs)\n",
        "        self.eeg = np.asarray(eeg, dtype=np.float32)\n",
        "        self.fnirs = np.asarray(fnirs, dtype=np.float32)\n",
        "        self.y = np.asarray(y, dtype=np.int64)\n",
        "    #Tells PyTorch how many samples (trials) exist.\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "    #Defines what to return for sample index i.\n",
        "    def __getitem__(self, i):\n",
        "      #Returns a dictionary for one sample:\n",
        "      #\"eeg\": tensor shaped (C_eeg, T_eeg)\n",
        "      #\"fnirs\": tensor shaped (C_fnirs, T_fnirs)\n",
        "        return {\n",
        "            \"eeg\": torch.from_numpy(self.eeg[i]).float(),\n",
        "            \"fnirs\": torch.from_numpy(self.fnirs[i]).float(),\n",
        "            \"y\": torch.tensor(self.y[i], dtype=torch.long)\n",
        "        }\n",
        "\n",
        "\n",
        "#It returns a dictionary so that one dataset can serve multiple models.\n",
        "#Teacher needs: eeg + fnirs + y\n",
        "#EEG student needs: eeg + y\n",
        "#fNIRS student needs: fnirs + y\n",
        "#can return any kind of object, but we prefer a dictionary here\n",
        "\n",
        "# ===========================================================\n",
        "# FILTER + NORMALIZE\n",
        "# ===========================================================\n",
        "\n",
        "#This function extracts only the two chosen classes and remaps labels to 0/1\n",
        "#Inputs:\n",
        "#full EEG array\n",
        "#full fNIRS array\n",
        "#original labels (0–7)\n",
        "#subject IDs per trial\n",
        "#two class IDs you want (e.g., 0 and 7)\n",
        "def global_binary_filter(eeg, fnirs, labels, subjects, c0, c1):\n",
        "\n",
        "    #Creates a boolean mask selecting trials belonging to either class.\n",
        "    #yani inja label bayad = task pair\n",
        "    mask = (labels == c0) | (labels == c1)\n",
        "    eeg = eeg[mask]\n",
        "    fnirs = fnirs[mask]\n",
        "    y = np.where(labels[mask] == c0, 0, 1).astype(np.int64) #Give me the task ID of every trial that survived the mask.\n",
        "    #example:task_ids = [0, 3, 7, 2, 7, 1]\n",
        "    #mask     = [T, F, T, F, T, F]\n",
        "    #task_ids[mask] = [0, 7, 7]\n",
        "    #then, If the task is c0, label it as class 0; otherwise label it as class 1.”\n",
        "\n",
        "    subj = subjects[mask]\n",
        "    #This keeps subject IDs aligned with the filtered trials.\n",
        "    return eeg, fnirs, y, subj\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Computes the mean per channel\n",
        "#Averages over:\n",
        "#axis=0 → all trials\n",
        "#axis=2 → all time points\n",
        "# =.  mean over all trials and all time of channel c\n",
        "def compute_mean_std(X):\n",
        "    mean = X.mean(axis=(0, 2), keepdims=True).astype(np.float32)\n",
        "    #keepdims=True:dont remove any dims. keep it as (1, C, 1)\n",
        "    std = (X.std(axis=(0, 2), keepdims=True) + 1e-8).astype(np.float32)\n",
        "    return mean, std\n",
        "    #Returns channel-wise normalization statistics, computed only from the data you pass i (e.g., training split only → leakage-free).\n",
        "\n",
        "def normalize(X, mean, std):\n",
        "    return ((X - mean) / std).astype(np.float32, copy=False)\n",
        "#summary:\n",
        "#For each channel independently:\n",
        "#Mean becomes ~0\n",
        "#Standard deviation becomes ~1\n",
        "#Scale differences across channels are removed\n",
        "# ===========================================================\n",
        "# MODELS\n",
        "# ===========================================================\n",
        "class ConvBranch(nn.Module):\n",
        "    def __init__(self, in_ch, base=64, dropout=0.3):\n",
        "      #in_ch → number of input channels\n",
        "      #EEG: e.g. 64 channels\n",
        "      #fNIRS: e.g. 24 channels\n",
        "      #base → number of convolution filters (model capacity)\n",
        "\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            #Conv1d: learns temporal patterns across time\n",
        "            nn.Conv1d(in_ch, base, kernel_size=7, padding=3),\n",
        "            #kernel_size=7: captures short-to-mid temporal dynamics(refer to the paper to see what values are best later\n",
        "            #padding=3: keeps time length unchanged?)\n",
        "\n",
        "            nn.BatchNorm1d(base),\n",
        "           #GELU:better than ReLU for nois signals\n",
        "            nn.GELU(),\n",
        "            nn.MaxPool1d(2),  #halves time resolution → robustness to noise\n",
        "\n",
        "\n",
        "            #another block because Builds hierarchical temporal features\n",
        "            nn.Conv1d(base, base, kernel_size=5, padding=2),\n",
        "            nn.BatchNorm1d(base),\n",
        "            nn.GELU(),\n",
        "            nn.MaxPool1d(2),\n",
        "            #third block:Doubles feature dimension (base → 2*base)\n",
        "            #AdaptiveAvgPool1d(1):\n",
        "            #Collapses entire time dimension\n",
        "            #Output becomes time-invariant\n",
        "            nn.Conv1d(base, base * 2, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm1d(base * 2),\n",
        "            nn.GELU(),\n",
        "            nn.AdaptiveAvgPool1d(1),\n",
        "            #output shape will be:(N, 2*base, 1)\n",
        "\n",
        "            nn.Flatten(), #(N,2*base)\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "        self.out_dim = base * 2   #This is used later when building classifiers.\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class Teacher_EEG_FNIRS(nn.Module):     #This is the privileged model.\n",
        "    def __init__(self, eeg_channels, fnirs_channels, num_classes=2, base_channels=64, dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.eeg_branch = ConvBranch(eeg_channels, base=base_channels, dropout=dropout)\n",
        "        self.fnirs_branch = ConvBranch(fnirs_channels, base=max(16, base_channels // 2), dropout=dropout) ##Smaller capacity for fNIRS\n",
        "        #because:\n",
        "        #1.fNIRS usually has fewer channels\n",
        "        #2.Lower temporal resolution\n",
        "        fusion_dim = self.eeg_branch.out_dim + self.fnirs_branch.out_dim\n",
        "        #This is late fusion:\n",
        "        #Learn features separately\n",
        "        #Combine only at the representation level\n",
        "\n",
        "\n",
        "\n",
        "        #classification head\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Linear(fusion_dim, 128),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "        #######flow########\n",
        "        #EEG   → ConvBranch → fe\n",
        "        #fNIRS → ConvBranch → ff\n",
        "        #[fe || ff] → classifier → logits\n",
        "\n",
        "    def forward(self, eeg, fnirs):\n",
        "        fe = self.eeg_branch(eeg)\n",
        "        ff = self.fnirs_branch(fnirs)\n",
        "        f = torch.cat([fe, ff], dim=1)\n",
        "        return self.head(f)\n",
        "\n",
        "class Student_EEG(nn.Module):   #this is what runs at deployment when only EEG is available\n",
        "\n",
        "#Same backbone as teacher EEG branch → fair comparison.\n",
        "    def __init__(self, eeg_channels, num_classes=2, base_channels=64, dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.branch = ConvBranch(eeg_channels, base=base_channels, dropout=dropout)\n",
        "        #classifier head\n",
        "        #Smaller than teacher → lower capacity → realistic deployment model.\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Linear(self.branch.out_dim, 128),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, eeg):\n",
        "        f = self.branch(eeg)\n",
        "        return self.head(f)\n",
        "\n",
        "class Student_fNIRS(nn.Module):\n",
        "#Symmetric to EEG student, but with lower capacity\n",
        "    def __init__(self, fnirs_channels, num_classes=2, base_channels=32, dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.branch = ConvBranch(fnirs_channels, base=max(16, base_channels), dropout=dropout)\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Linear(self.branch.out_dim, 128),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, fnirs):\n",
        "        f = self.branch(fnirs)\n",
        "        return self.head(f)\n",
        "\n",
        "# ===========================================================\n",
        "# TRAIN / EVAL HELPERS\n",
        "# ===========================================================\n",
        "def train_teacher_epoch(model, loader, opt, crit):\n",
        "  #This trains one epoch of the multimodal teacher (EEG + fNIRS)\n",
        "\n",
        "    model.train()   #Put model in training mode\n",
        "    for b in loader:      #Each b is a dictionary from your MI_Dataset\n",
        "        eeg = b[\"eeg\"].to(DEVICE)   #Move data to GPU/CPU: Model and data are on the same device\n",
        "        fn = b[\"fnirs\"].to(DEVICE)\n",
        "        y = b[\"y\"].to(DEVICE)\n",
        "        opt.zero_grad()\n",
        "        logits = model(eeg, fn)\n",
        "        loss = crit(logits, y)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_teacher(model, loader):  #Evaluates teacher without training\n",
        "    model.eval()\n",
        "    correct = total = 0\n",
        "    for b in loader:\n",
        "        eeg = b[\"eeg\"].to(DEVICE)\n",
        "        fn = b[\"fnirs\"].to(DEVICE)\n",
        "        y = b[\"y\"].to(DEVICE)\n",
        "        logits = model(eeg, fn)\n",
        "        correct += (logits.argmax(1) == y).sum().item()\n",
        "        total += y.size(0)\n",
        "    return correct / max(total, 1)\n",
        "\n",
        "def train_eeg_baseline_epoch(student, loader, opt, crit):   #This trains an EEG-only student, without KD.\n",
        "    student.train()\n",
        "    for b in loader:\n",
        "        eeg = b[\"eeg\"].to(DEVICE)\n",
        "        y = b[\"y\"].to(DEVICE)\n",
        "        opt.zero_grad()\n",
        "        logits = student(eeg)\n",
        "        loss = crit(logits, y)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "def train_fnirs_baseline_epoch(student, loader, opt, crit):   #This trains an fnirs only student\n",
        "    student.train()\n",
        "    for b in loader:\n",
        "        fn = b[\"fnirs\"].to(DEVICE)\n",
        "        y = b[\"y\"].to(DEVICE)\n",
        "        opt.zero_grad()\n",
        "        logits = student(fn)\n",
        "        loss = crit(logits, y)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_eeg(student, loader):    #evaluating eeg\n",
        "    student.eval()\n",
        "    correct = total = 0\n",
        "    for b in loader:\n",
        "        eeg = b[\"eeg\"].to(DEVICE)\n",
        "        y = b[\"y\"].to(DEVICE)\n",
        "        logits = student(eeg)\n",
        "        correct += (logits.argmax(1) == y).sum().item()\n",
        "        total += y.size(0)\n",
        "    return correct / max(total, 1)\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_fnirs(student, loader):      #evaluating fnirs\n",
        "    student.eval()\n",
        "    correct = total = 0\n",
        "    for b in loader:\n",
        "        fn = b[\"fnirs\"].to(DEVICE)\n",
        "        y = b[\"y\"].to(DEVICE)\n",
        "        logits = student(fn)\n",
        "        correct += (logits.argmax(1) == y).sum().item()\n",
        "        total += y.size(0)\n",
        "    return correct / max(total, 1)\n",
        "\n",
        "# ===========================================================\n",
        "# KD (UPGRADED): warm-start + teacher confidence gating\n",
        "# ===========================================================\n",
        "def confidence_mask(teacher_logits, thresh=0.7):    #only trust the teacher when it’s confident\n",
        "    probs = F.softmax(teacher_logits, dim=1)\n",
        "    conf, _ = probs.max(dim=1)\n",
        "    return conf >= thresh\n",
        "\n",
        "def kd_loss_vec(student_logits, teacher_logits, y, alpha=DISTILL_ALPHA, T=DISTILL_T):\n",
        "\n",
        "  #Computes a vector of losses (one loss per sample), combining:\n",
        "  #normal supervised loss (CE with ground-truth labels)\n",
        "  #KD loss (KL divergence between student and teacher softened probabilities)\n",
        "    ce = F.cross_entropy(student_logits, y, reduction=\"none\")\n",
        "    log_p_s = F.log_softmax(student_logits / T, dim=1)  #Divides logits by temperature T to “soften” them\n",
        "    p_t = F.softmax(teacher_logits / T, dim=1)\n",
        "    kl = F.kl_div(log_p_s, p_t, reduction=\"none\").sum(dim=1) * (T * T)\n",
        "    return alpha * ce + (1 - alpha) * kl\n",
        "\n",
        "def train_eeg_kd_epoch(student, teacher, loader, opt, epoch,\n",
        "                       warmup_epochs=WARMUP_EPOCHS, conf_thresh=KD_CONF_THRESH):\n",
        "    student.train()\n",
        "    teacher.eval()\n",
        "    for b in loader:\n",
        "        eeg = b[\"eeg\"].to(DEVICE)\n",
        "        fn = b[\"fnirs\"].to(DEVICE)\n",
        "        y = b[\"y\"].to(DEVICE)\n",
        "\n",
        "        opt.zero_grad()\n",
        "        s_logits = student(eeg)\n",
        "\n",
        "        if epoch < warmup_epochs:\n",
        "            loss = F.cross_entropy(s_logits, y)\n",
        "        else:\n",
        "            with torch.no_grad():\n",
        "                t_logits = teacher(eeg, fn)\n",
        "                m = confidence_mask(t_logits, conf_thresh)\n",
        "\n",
        "            if m.sum().item() == 0:\n",
        "                loss = F.cross_entropy(s_logits, y)\n",
        "            else:\n",
        "                kd = kd_loss_vec(s_logits[m], t_logits[m], y[m]).mean()\n",
        "                ce = F.cross_entropy(s_logits, y)\n",
        "                loss = 0.5 * ce + 0.5 * kd\n",
        "\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "def train_fnirs_kd_epoch(student, teacher, loader, opt, epoch,\n",
        "                         warmup_epochs=WARMUP_EPOCHS, conf_thresh=KD_CONF_THRESH):\n",
        "    student.train()\n",
        "    teacher.eval()\n",
        "    for b in loader:\n",
        "        eeg = b[\"eeg\"].to(DEVICE)\n",
        "        fn = b[\"fnirs\"].to(DEVICE)\n",
        "        y = b[\"y\"].to(DEVICE)\n",
        "\n",
        "        opt.zero_grad()\n",
        "        s_logits = student(fn)\n",
        "\n",
        "        if epoch < warmup_epochs:\n",
        "            loss = F.cross_entropy(s_logits, y)\n",
        "        else:\n",
        "            with torch.no_grad():\n",
        "                t_logits = teacher(eeg, fn)\n",
        "                m = confidence_mask(t_logits, conf_thresh)\n",
        "\n",
        "            if m.sum().item() == 0:\n",
        "                loss = F.cross_entropy(s_logits, y)\n",
        "            else:\n",
        "                kd = kd_loss_vec(s_logits[m], t_logits[m], y[m]).mean()\n",
        "                ce = F.cross_entropy(s_logits, y)\n",
        "                loss = 0.5 * ce + 0.5 * kd\n",
        "\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "# ===========================================================\n",
        "# GLOBAL TEACHER PRETRAIN (exclude target subject)\n",
        "# ===========================================================\n",
        "def pretrain_global_teacher(exclude_subject, eeg_all, fnirs_all, y_all, subj_all,\n",
        "                            eeg_channels, fnirs_channels):\n",
        "    mask = subj_all != exclude_subject\n",
        "    eeg = eeg_all[mask]\n",
        "    fn = fnirs_all[mask]\n",
        "    y = y_all[mask]\n",
        "\n",
        "    # normalize on pretrain pool only\n",
        "    eeg_m, eeg_s = compute_mean_std(eeg)\n",
        "    fn_m, fn_s = compute_mean_std(fn)\n",
        "    eeg = normalize(eeg, eeg_m, eeg_s)\n",
        "    fn = normalize(fn, fn_m, fn_s)\n",
        "\n",
        "    loader = DataLoader(MI_Dataset(eeg, fn, y), batch_size=64, shuffle=True)\n",
        "\n",
        "    teacher = Teacher_EEG_FNIRS(\n",
        "        eeg_channels=eeg_channels,\n",
        "        fnirs_channels=fnirs_channels,\n",
        "        num_classes=2,\n",
        "        base_channels=BASE_CHANNELS,\n",
        "        dropout=0.1\n",
        "    ).to(DEVICE)\n",
        "\n",
        "    opt = torch.optim.AdamW(teacher.parameters(), lr=LR_GLOBAL, weight_decay=WEIGHT_DECAY)\n",
        "    crit = nn.CrossEntropyLoss()\n",
        "\n",
        "    for _ in range(EPOCHS_GLOBAL_PRETRAIN):\n",
        "        train_teacher_epoch(teacher, loader, opt, crit)\n",
        "\n",
        "    return teacher\n",
        "\n",
        "# ===========================================================\n",
        "# BUILD GLOBAL BINARY ARRAYS\n",
        "# ===========================================================\n",
        "GLOBAL_EEG, GLOBAL_FNIRS, GLOBAL_Y, GLOBAL_SUBJ = global_binary_filter(\n",
        "    eeg_all, fnirs_all, labels_all, subject_ids_all,\n",
        "    BINARY_CLASSES[0], BINARY_CLASSES[1]\n",
        ")\n",
        "\n",
        "print(\"\\nGLOBAL DATASET READY\")\n",
        "print(f\"Trials: {len(GLOBAL_Y)} | Subjects: {len(np.unique(GLOBAL_SUBJ))}\")\n",
        "print(\"Class0:\", int((GLOBAL_Y == 0).sum()), \"Class1:\", int((GLOBAL_Y == 1).sum()))\n",
        "\n",
        "# ===========================================================\n",
        "# MAIN RUN\n",
        "# ===========================================================\n",
        "print(\"\\n\" + \"=\" * 100)\n",
        "print(\"LEAKAGE-FREE: Teacher (EEG+fNIRS) -> EEG-student + fNIRS-student (baseline vs KD-upgraded vs VAL-gated)\")\n",
        "print(\"=\" * 100)\n",
        "\n",
        "teacher_means = []\n",
        "eeg_base_means, eeg_kd_means, eeg_gate_means = [], [], []\n",
        "fn_base_means, fn_kd_means, fn_gate_means = [], [], []\n",
        "\n",
        "for subj in np.unique(GLOBAL_SUBJ):\n",
        "    m = GLOBAL_SUBJ == subj\n",
        "    eeg_s = GLOBAL_EEG[m]\n",
        "    fn_s  = GLOBAL_FNIRS[m]\n",
        "    y_s   = GLOBAL_Y[m]\n",
        "\n",
        "    print(f\"\\nSubject {subj} | trials={len(y_s)}\")\n",
        "    if len(np.unique(y_s)) < 2:\n",
        "        print(\"  Skipping: only one class present.\")\n",
        "        continue\n",
        "\n",
        "    # Global teacher pretrain on other subjects (no leakage)\n",
        "    teacher_global = pretrain_global_teacher(\n",
        "        exclude_subject=subj,\n",
        "        eeg_all=GLOBAL_EEG, fnirs_all=GLOBAL_FNIRS, y_all=GLOBAL_Y, subj_all=GLOBAL_SUBJ,\n",
        "        eeg_channels=eeg_s.shape[1],\n",
        "        fnirs_channels=fn_s.shape[1],\n",
        "    )\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n",
        "\n",
        "    fold_T = []\n",
        "\n",
        "    fold_eeg_base, fold_eeg_kd, fold_eeg_gate = [], [], []\n",
        "    fold_fn_base,  fold_fn_kd,  fold_fn_gate  = [], [], []\n",
        "\n",
        "    for fold, (train_idx, test_idx) in enumerate(skf.split(np.zeros(len(y_s)), y_s), 1):\n",
        "        # Inner split train -> train/val\n",
        "        sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=SEED)\n",
        "        tr_sub, va_sub = next(sss.split(np.zeros(len(train_idx)), y_s[train_idx]))\n",
        "        idx_tr = train_idx[tr_sub]\n",
        "        idx_va = train_idx[va_sub]\n",
        "        idx_te = test_idx\n",
        "\n",
        "        eeg_tr, fn_tr, y_tr = eeg_s[idx_tr], fn_s[idx_tr], y_s[idx_tr]\n",
        "        eeg_va, fn_va, y_va = eeg_s[idx_va], fn_s[idx_va], y_s[idx_va]\n",
        "        eeg_te, fn_te, y_te = eeg_s[idx_te], fn_s[idx_te], y_s[idx_te]\n",
        "\n",
        "        # Fold-train-only normalization (leakage-free)\n",
        "        eeg_m, eeg_std = compute_mean_std(eeg_tr)\n",
        "        fn_m, fn_std   = compute_mean_std(fn_tr)\n",
        "\n",
        "        eeg_tr = normalize(eeg_tr, eeg_m, eeg_std)\n",
        "        eeg_va = normalize(eeg_va, eeg_m, eeg_std)\n",
        "        eeg_te = normalize(eeg_te, eeg_m, eeg_std)\n",
        "\n",
        "        fn_tr  = normalize(fn_tr, fn_m, fn_std)\n",
        "        fn_va  = normalize(fn_va, fn_m, fn_std)\n",
        "        fn_te  = normalize(fn_te, fn_m, fn_std)\n",
        "\n",
        "        tr_loader = DataLoader(MI_Dataset(eeg_tr, fn_tr, y_tr), batch_size=BATCH_SIZE, shuffle=True)\n",
        "        va_loader = DataLoader(MI_Dataset(eeg_va, fn_va, y_va), batch_size=BATCH_SIZE, shuffle=False)\n",
        "        te_loader = DataLoader(MI_Dataset(eeg_te, fn_te, y_te), batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "        # Weighted CE from train split (used for teacher + baselines)\n",
        "        counts = np.bincount(y_tr, minlength=2)\n",
        "        if counts.min() == 0:\n",
        "            crit = nn.CrossEntropyLoss()\n",
        "        else:\n",
        "            w = (1.0 / counts)\n",
        "            w = w / w.sum() * 2.0\n",
        "            crit = nn.CrossEntropyLoss(weight=torch.tensor(w, dtype=torch.float32, device=DEVICE))\n",
        "\n",
        "        # -----------------------\n",
        "        # Teacher fold fine-tune (init from global)\n",
        "        # -----------------------\n",
        "        teacher = Teacher_EEG_FNIRS(\n",
        "            eeg_channels=eeg_tr.shape[1],\n",
        "            fnirs_channels=fn_tr.shape[1],\n",
        "            num_classes=2,\n",
        "            base_channels=BASE_CHANNELS,\n",
        "            dropout=0.1\n",
        "        ).to(DEVICE)\n",
        "        teacher.load_state_dict(teacher_global.state_dict())\n",
        "\n",
        "        opt_t = torch.optim.AdamW(teacher.parameters(), lr=LR_TEACHER_FT, weight_decay=WEIGHT_DECAY)\n",
        "\n",
        "        best_va_t, best_state_t, bad_t = -1.0, None, 0\n",
        "        for _ in range(EPOCHS_TEACHER_FT):\n",
        "            train_teacher_epoch(teacher, tr_loader, opt_t, crit)\n",
        "            va_t = eval_teacher(teacher, va_loader)\n",
        "            if va_t > best_va_t:\n",
        "                best_va_t = va_t\n",
        "                best_state_t = {k: v.detach().cpu().clone() for k, v in teacher.state_dict().items()}\n",
        "                bad_t = 0\n",
        "            else:\n",
        "                bad_t += 1\n",
        "                if bad_t >= PATIENCE:\n",
        "                    break\n",
        "        if best_state_t is not None:\n",
        "            teacher.load_state_dict(best_state_t)\n",
        "\n",
        "        t_test = eval_teacher(teacher, te_loader)\n",
        "        fold_T.append(t_test)\n",
        "\n",
        "        # ==========================================================\n",
        "        # EEG STUDENT: baseline CE\n",
        "        # ==========================================================\n",
        "        eeg_base = Student_EEG(eeg_channels=eeg_tr.shape[1], base_channels=BASE_CHANNELS, dropout=0.3).to(DEVICE)\n",
        "        opt_eb = torch.optim.AdamW(eeg_base.parameters(), lr=LR_STUDENT, weight_decay=WEIGHT_DECAY)\n",
        "\n",
        "        best_va_eb, best_state_eb, bad = -1.0, None, 0\n",
        "        for _ in range(EPOCHS_STUDENT):\n",
        "            train_eeg_baseline_epoch(eeg_base, tr_loader, opt_eb, crit)\n",
        "            va = eval_eeg(eeg_base, va_loader)\n",
        "            if va > best_va_eb:\n",
        "                best_va_eb = va\n",
        "                best_state_eb = {k: v.detach().cpu().clone() for k, v in eeg_base.state_dict().items()}\n",
        "                bad = 0\n",
        "            else:\n",
        "                bad += 1\n",
        "                if bad >= PATIENCE:\n",
        "                    break\n",
        "        if best_state_eb is not None:\n",
        "            eeg_base.load_state_dict(best_state_eb)\n",
        "        eeg_base_test = eval_eeg(eeg_base, te_loader)\n",
        "\n",
        "        # ==========================================================\n",
        "        # EEG STUDENT: KD (UPGRADED warm + confidence-gated)\n",
        "        # ==========================================================\n",
        "        eeg_kd = Student_EEG(eeg_channels=eeg_tr.shape[1], base_channels=BASE_CHANNELS, dropout=0.3).to(DEVICE)\n",
        "        opt_ek = torch.optim.AdamW(eeg_kd.parameters(), lr=LR_STUDENT, weight_decay=WEIGHT_DECAY)\n",
        "\n",
        "        best_va_ek, best_state_ek, bad = -1.0, None, 0\n",
        "        for ep in range(EPOCHS_STUDENT):\n",
        "            train_eeg_kd_epoch(eeg_kd, teacher, tr_loader, opt_ek, epoch=ep)\n",
        "            va = eval_eeg(eeg_kd, va_loader)\n",
        "            if va > best_va_ek:\n",
        "                best_va_ek = va\n",
        "                best_state_ek = {k: v.detach().cpu().clone() for k, v in eeg_kd.state_dict().items()}\n",
        "                bad = 0\n",
        "            else:\n",
        "                bad += 1\n",
        "                if bad >= PATIENCE:\n",
        "                    break\n",
        "        if best_state_ek is not None:\n",
        "            eeg_kd.load_state_dict(best_state_ek)\n",
        "        eeg_kd_test = eval_eeg(eeg_kd, te_loader)\n",
        "\n",
        "        # VAL gate: choose baseline or KD model\n",
        "        if USE_VAL_GATE and (best_va_ek > best_va_eb + VAL_GATE_MARGIN):\n",
        "            eeg_gate_test = eeg_kd_test\n",
        "        else:\n",
        "            eeg_gate_test = eeg_base_test\n",
        "\n",
        "        # ==========================================================\n",
        "        # fNIRS STUDENT: baseline CE\n",
        "        # ==========================================================\n",
        "        fn_base = Student_fNIRS(fnirs_channels=fn_tr.shape[1], base_channels=32, dropout=0.3).to(DEVICE)\n",
        "        opt_fb = torch.optim.AdamW(fn_base.parameters(), lr=LR_STUDENT, weight_decay=WEIGHT_DECAY)\n",
        "\n",
        "        best_va_fb, best_state_fb, bad = -1.0, None, 0\n",
        "        for _ in range(EPOCHS_STUDENT):\n",
        "            train_fnirs_baseline_epoch(fn_base, tr_loader, opt_fb, crit)\n",
        "            va = eval_fnirs(fn_base, va_loader)\n",
        "            if va > best_va_fb:\n",
        "                best_va_fb = va\n",
        "                best_state_fb = {k: v.detach().cpu().clone() for k, v in fn_base.state_dict().items()}\n",
        "                bad = 0\n",
        "            else:\n",
        "                bad += 1\n",
        "                if bad >= PATIENCE:\n",
        "                    break\n",
        "        if best_state_fb is not None:\n",
        "            fn_base.load_state_dict(best_state_fb)\n",
        "        fn_base_test = eval_fnirs(fn_base, te_loader)\n",
        "\n",
        "        # ==========================================================\n",
        "        # fNIRS STUDENT: KD (UPGRADED warm + confidence-gated)\n",
        "        # ==========================================================\n",
        "        fn_kd = Student_fNIRS(fnirs_channels=fn_tr.shape[1], base_channels=32, dropout=0.3).to(DEVICE)\n",
        "        opt_fk = torch.optim.AdamW(fn_kd.parameters(), lr=LR_STUDENT, weight_decay=WEIGHT_DECAY)\n",
        "\n",
        "        best_va_fk, best_state_fk, bad = -1.0, None, 0\n",
        "        for ep in range(EPOCHS_STUDENT):\n",
        "            train_fnirs_kd_epoch(fn_kd, teacher, tr_loader, opt_fk, epoch=ep)\n",
        "            va = eval_fnirs(fn_kd, va_loader)\n",
        "            if va > best_va_fk:\n",
        "                best_va_fk = va\n",
        "                best_state_fk = {k: v.detach().cpu().clone() for k, v in fn_kd.state_dict().items()}\n",
        "                bad = 0\n",
        "            else:\n",
        "                bad += 1\n",
        "                if bad >= PATIENCE:\n",
        "                    break\n",
        "        if best_state_fk is not None:\n",
        "            fn_kd.load_state_dict(best_state_fk)\n",
        "        fn_kd_test = eval_fnirs(fn_kd, te_loader)\n",
        "\n",
        "        # VAL gate for fNIRS\n",
        "        if USE_VAL_GATE and (best_va_fk > best_va_fb + VAL_GATE_MARGIN):\n",
        "            fn_gate_test = fn_kd_test\n",
        "        else:\n",
        "            fn_gate_test = fn_base_test\n",
        "\n",
        "        # Collect fold results\n",
        "        fold_eeg_base.append(eeg_base_test)\n",
        "        fold_eeg_kd.append(eeg_kd_test)\n",
        "        fold_eeg_gate.append(eeg_gate_test)\n",
        "\n",
        "        fold_fn_base.append(fn_base_test)\n",
        "        fold_fn_kd.append(fn_kd_test)\n",
        "        fold_fn_gate.append(fn_gate_test)\n",
        "\n",
        "        print(f\" Fold {fold}/{N_FOLDS} | T={t_test:.3f} | \"\n",
        "              f\"EEG: base={eeg_base_test:.3f} kd={eeg_kd_test:.3f} gate={eeg_gate_test:.3f} | \"\n",
        "              f\"fNIRS: base={fn_base_test:.3f} kd={fn_kd_test:.3f} gate={fn_gate_test:.3f}\")\n",
        "\n",
        "    # Subject means\n",
        "    Tm = float(np.mean(fold_T))\n",
        "\n",
        "    ebm, ekm, egm = float(np.mean(fold_eeg_base)), float(np.mean(fold_eeg_kd)), float(np.mean(fold_eeg_gate))\n",
        "    fbm, fkm, fgm = float(np.mean(fold_fn_base)),  float(np.mean(fold_fn_kd)),  float(np.mean(fold_fn_gate))\n",
        "\n",
        "    teacher_means.append(Tm)\n",
        "    eeg_base_means.append(ebm); eeg_kd_means.append(ekm); eeg_gate_means.append(egm)\n",
        "    fn_base_means.append(fbm);  fn_kd_means.append(fkm);  fn_gate_means.append(fgm)\n",
        "\n",
        "    print(f\"Subject {subj} means | T={Tm:.3f} | \"\n",
        "          f\"EEG(base/kd/gate)={ebm:.3f}/{ekm:.3f}/{egm:.3f} | \"\n",
        "          f\"fNIRS(base/kd/gate)={fbm:.3f}/{fkm:.3f}/{fgm:.3f}\")\n",
        "\n",
        "# Final summary\n",
        "print(\"\\n\" + \"=\" * 100)\n",
        "print(\"FINAL SUMMARY (UPGRADED KD, leakage-free)\")\n",
        "print(\"=\" * 100)\n",
        "print(f\"Subjects evaluated: {len(teacher_means)}\")\n",
        "print(f\"Teacher Overall mean        = {np.mean(teacher_means):.3f} ± {np.std(teacher_means):.3f}\")\n",
        "\n",
        "print(f\"EEG-only Baseline mean      = {np.mean(eeg_base_means):.3f} ± {np.std(eeg_base_means):.3f}\")\n",
        "print(f\"EEG-only KD-upgraded mean   = {np.mean(eeg_kd_means):.3f} ± {np.std(eeg_kd_means):.3f}\")\n",
        "print(f\"EEG-only VAL-gated mean     = {np.mean(eeg_gate_means):.3f} ± {np.std(eeg_gate_means):.3f}\")\n",
        "\n",
        "print(f\"fNIRS-only Baseline mean    = {np.mean(fn_base_means):.3f} ± {np.std(fn_base_means):.3f}\")\n",
        "print(f\"fNIRS-only KD-upgraded mean = {np.mean(fn_kd_means):.3f} ± {np.std(fn_kd_means):.3f}\")\n",
        "print(f\"fNIRS-only VAL-gated mean   = {np.mean(fn_gate_means):.3f} ± {np.std(fn_gate_means):.3f}\")\n",
        "\n",
        "print(f\"(KD warmup={WARMUP_EPOCHS} epochs, conf_thresh={KD_CONF_THRESH}, VAL gate margin={VAL_GATE_MARGIN}, gate={USE_VAL_GATE})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1x4lqIjQuBU",
        "outputId": "0d4eda08-49a8-4f09-b1ed-c717cdaca532"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "\n",
            "GLOBAL DATASET READY\n",
            "Trials: 1279 | Subjects: 16\n",
            "Class0: 640 Class1: 639\n",
            "\n",
            "====================================================================================================\n",
            "LEAKAGE-FREE: Teacher (EEG+fNIRS) -> EEG-student + fNIRS-student (baseline vs KD-upgraded vs VAL-gated)\n",
            "====================================================================================================\n",
            "\n",
            "Subject 1 | trials=90\n",
            " Fold 1/5 | T=0.556 | EEG: base=0.611 kd=0.556 gate=0.611 | fNIRS: base=0.500 kd=0.500 gate=0.500\n",
            " Fold 2/5 | T=0.556 | EEG: base=0.667 kd=0.556 gate=0.556 | fNIRS: base=0.500 kd=0.500 gate=0.500\n",
            " Fold 3/5 | T=0.389 | EEG: base=0.556 kd=0.444 gate=0.556 | fNIRS: base=0.500 kd=0.500 gate=0.500\n",
            " Fold 4/5 | T=0.444 | EEG: base=0.667 kd=0.778 gate=0.667 | fNIRS: base=0.389 kd=0.444 gate=0.389\n",
            " Fold 5/5 | T=0.611 | EEG: base=0.500 kd=0.722 gate=0.722 | fNIRS: base=0.500 kd=0.500 gate=0.500\n",
            "Subject 1 means | T=0.511 | EEG(base/kd/gate)=0.600/0.611/0.622 | fNIRS(base/kd/gate)=0.478/0.489/0.478\n",
            "\n",
            "Subject 2 | trials=80\n",
            " Fold 1/5 | T=0.562 | EEG: base=0.375 kd=0.500 gate=0.375 | fNIRS: base=0.500 kd=0.562 gate=0.562\n",
            " Fold 2/5 | T=0.625 | EEG: base=0.500 kd=0.500 gate=0.500 | fNIRS: base=0.500 kd=0.438 gate=0.438\n",
            " Fold 3/5 | T=0.375 | EEG: base=0.500 kd=0.438 gate=0.438 | fNIRS: base=0.500 kd=0.500 gate=0.500\n",
            " Fold 4/5 | T=0.750 | EEG: base=0.438 kd=0.500 gate=0.500 | fNIRS: base=0.438 kd=0.500 gate=0.438\n",
            " Fold 5/5 | T=0.375 | EEG: base=0.500 kd=0.500 gate=0.500 | fNIRS: base=0.500 kd=0.500 gate=0.500\n",
            "Subject 2 means | T=0.537 | EEG(base/kd/gate)=0.463/0.487/0.463 | fNIRS(base/kd/gate)=0.487/0.500/0.487\n",
            "\n",
            "Subject 3 | trials=80\n",
            " Fold 1/5 | T=0.750 | EEG: base=0.438 kd=0.500 gate=0.438 | fNIRS: base=0.500 kd=0.500 gate=0.500\n",
            " Fold 2/5 | T=0.625 | EEG: base=0.500 kd=0.688 gate=0.688 | fNIRS: base=0.500 kd=0.500 gate=0.500\n",
            " Fold 3/5 | T=0.625 | EEG: base=0.500 kd=0.500 gate=0.500 | fNIRS: base=0.500 kd=0.625 gate=0.625\n",
            " Fold 4/5 | T=0.500 | EEG: base=0.500 kd=0.500 gate=0.500 | fNIRS: base=0.500 kd=0.562 gate=0.562\n",
            " Fold 5/5 | T=0.688 | EEG: base=0.500 kd=0.500 gate=0.500 | fNIRS: base=0.500 kd=0.500 gate=0.500\n",
            "Subject 3 means | T=0.637 | EEG(base/kd/gate)=0.487/0.537/0.525 | fNIRS(base/kd/gate)=0.500/0.537/0.537\n",
            "\n",
            "Subject 4 | trials=80\n",
            " Fold 1/5 | T=0.562 | EEG: base=0.750 kd=0.500 gate=0.750 | fNIRS: base=0.500 kd=0.500 gate=0.500\n",
            " Fold 2/5 | T=0.625 | EEG: base=0.375 kd=0.438 gate=0.375 | fNIRS: base=0.500 kd=0.500 gate=0.500\n",
            " Fold 3/5 | T=0.625 | EEG: base=0.500 kd=0.625 gate=0.625 | fNIRS: base=0.562 kd=0.562 gate=0.562\n",
            " Fold 4/5 | T=0.562 | EEG: base=0.500 kd=0.500 gate=0.500 | fNIRS: base=0.438 kd=0.500 gate=0.438\n",
            " Fold 5/5 | T=0.625 | EEG: base=0.500 kd=0.625 gate=0.500 | fNIRS: base=0.500 kd=0.500 gate=0.500\n",
            "Subject 4 means | T=0.600 | EEG(base/kd/gate)=0.525/0.537/0.550 | fNIRS(base/kd/gate)=0.500/0.512/0.500\n",
            "\n",
            "Subject 5 | trials=80\n",
            " Fold 1/5 | T=0.562 | EEG: base=0.500 kd=0.438 gate=0.500 | fNIRS: base=0.500 kd=0.500 gate=0.500\n",
            " Fold 2/5 | T=0.562 | EEG: base=0.375 kd=0.500 gate=0.375 | fNIRS: base=0.500 kd=0.375 gate=0.375\n",
            " Fold 3/5 | T=0.688 | EEG: base=0.500 kd=0.375 gate=0.375 | fNIRS: base=0.500 kd=0.500 gate=0.500\n",
            " Fold 4/5 | T=0.625 | EEG: base=0.500 kd=0.500 gate=0.500 | fNIRS: base=0.500 kd=0.562 gate=0.500\n",
            " Fold 5/5 | T=0.562 | EEG: base=0.500 kd=0.500 gate=0.500 | fNIRS: base=0.500 kd=0.500 gate=0.500\n",
            "Subject 5 means | T=0.600 | EEG(base/kd/gate)=0.475/0.463/0.450 | fNIRS(base/kd/gate)=0.500/0.487/0.475\n",
            "\n",
            "Subject 6 | trials=80\n",
            " Fold 1/5 | T=0.438 | EEG: base=0.438 kd=0.438 gate=0.438 | fNIRS: base=0.500 kd=0.375 gate=0.375\n",
            " Fold 2/5 | T=0.688 | EEG: base=0.438 kd=0.375 gate=0.375 | fNIRS: base=0.500 kd=0.688 gate=0.688\n",
            " Fold 3/5 | T=0.625 | EEG: base=0.500 kd=0.500 gate=0.500 | fNIRS: base=0.500 kd=0.500 gate=0.500\n",
            " Fold 4/5 | T=0.500 | EEG: base=0.500 kd=0.625 gate=0.625 | fNIRS: base=0.500 kd=0.500 gate=0.500\n",
            " Fold 5/5 | T=0.500 | EEG: base=0.500 kd=0.500 gate=0.500 | fNIRS: base=0.500 kd=0.500 gate=0.500\n",
            "Subject 6 means | T=0.550 | EEG(base/kd/gate)=0.475/0.487/0.487 | fNIRS(base/kd/gate)=0.500/0.512/0.512\n",
            "\n",
            "Subject 7 | trials=80\n",
            " Fold 1/5 | T=0.688 | EEG: base=0.500 kd=0.812 gate=0.812 | fNIRS: base=0.500 kd=0.688 gate=0.688\n",
            " Fold 2/5 | T=0.625 | EEG: base=0.375 kd=0.500 gate=0.375 | fNIRS: base=0.562 kd=0.562 gate=0.562\n",
            " Fold 3/5 | T=0.688 | EEG: base=0.500 kd=0.812 gate=0.812 | fNIRS: base=0.812 kd=0.688 gate=0.688\n",
            " Fold 4/5 | T=0.750 | EEG: base=0.562 kd=0.562 gate=0.562 | fNIRS: base=0.688 kd=0.500 gate=0.688\n",
            " Fold 5/5 | T=0.875 | EEG: base=0.500 kd=0.500 gate=0.500 | fNIRS: base=0.875 kd=0.562 gate=0.875\n",
            "Subject 7 means | T=0.725 | EEG(base/kd/gate)=0.487/0.637/0.613 | fNIRS(base/kd/gate)=0.688/0.600/0.700\n",
            "\n",
            "Subject 8 | trials=79\n",
            " Fold 1/5 | T=0.562 | EEG: base=0.500 kd=0.500 gate=0.500 | fNIRS: base=0.625 kd=0.500 gate=0.625\n",
            " Fold 2/5 | T=0.500 | EEG: base=0.500 kd=0.500 gate=0.500 | fNIRS: base=0.500 kd=0.500 gate=0.500\n",
            " Fold 3/5 | T=0.688 | EEG: base=0.500 kd=0.500 gate=0.500 | fNIRS: base=0.500 kd=0.500 gate=0.500\n",
            " Fold 4/5 | T=0.438 | EEG: base=0.500 kd=0.438 gate=0.438 | fNIRS: base=0.188 kd=0.500 gate=0.188\n",
            " Fold 5/5 | T=0.667 | EEG: base=0.400 kd=0.467 gate=0.400 | fNIRS: base=0.467 kd=0.467 gate=0.467\n",
            "Subject 8 means | T=0.571 | EEG(base/kd/gate)=0.480/0.481/0.467 | fNIRS(base/kd/gate)=0.456/0.493/0.456\n",
            "\n",
            "Subject 9 | trials=80\n",
            " Fold 1/5 | T=0.750 | EEG: base=0.500 kd=0.500 gate=0.500 | fNIRS: base=0.500 kd=0.438 gate=0.500\n",
            " Fold 2/5 | T=0.562 | EEG: base=0.500 kd=0.500 gate=0.500 | fNIRS: base=0.500 kd=0.562 gate=0.562\n",
            " Fold 3/5 | T=0.500 | EEG: base=0.500 kd=0.625 gate=0.500 | fNIRS: base=0.500 kd=0.500 gate=0.500\n",
            " Fold 4/5 | T=0.562 | EEG: base=0.312 kd=0.375 gate=0.312 | fNIRS: base=0.438 kd=0.438 gate=0.438\n",
            " Fold 5/5 | T=0.500 | EEG: base=0.375 kd=0.375 gate=0.375 | fNIRS: base=0.500 kd=0.500 gate=0.500\n",
            "Subject 9 means | T=0.575 | EEG(base/kd/gate)=0.438/0.475/0.438 | fNIRS(base/kd/gate)=0.487/0.487/0.500\n",
            "\n",
            "Subject 11 | trials=70\n",
            " Fold 1/5 | T=0.714 | EEG: base=0.500 kd=0.643 gate=0.643 | fNIRS: base=0.500 kd=0.429 gate=0.500\n",
            " Fold 2/5 | T=0.714 | EEG: base=0.500 kd=0.714 gate=0.714 | fNIRS: base=0.500 kd=0.571 gate=0.571\n",
            " Fold 3/5 | T=0.714 | EEG: base=0.357 kd=0.500 gate=0.357 | fNIRS: base=0.500 kd=0.500 gate=0.500\n",
            " Fold 4/5 | T=0.714 | EEG: base=0.500 kd=0.571 gate=0.571 | fNIRS: base=0.500 kd=0.571 gate=0.571\n",
            " Fold 5/5 | T=0.714 | EEG: base=0.429 kd=0.714 gate=0.429 | fNIRS: base=0.500 kd=0.500 gate=0.500\n",
            "Subject 11 means | T=0.714 | EEG(base/kd/gate)=0.457/0.629/0.543 | fNIRS(base/kd/gate)=0.500/0.514/0.529\n",
            "\n",
            "Subject 12 | trials=80\n",
            " Fold 1/5 | T=0.875 | EEG: base=0.562 kd=0.562 gate=0.562 | fNIRS: base=0.438 kd=0.500 gate=0.500\n",
            " Fold 2/5 | T=0.625 | EEG: base=0.500 kd=0.500 gate=0.500 | fNIRS: base=0.375 kd=0.500 gate=0.375\n",
            " Fold 3/5 | T=0.562 | EEG: base=0.562 kd=0.500 gate=0.562 | fNIRS: base=0.500 kd=0.438 gate=0.500\n",
            " Fold 4/5 | T=0.375 | EEG: base=0.500 kd=0.375 gate=0.500 | fNIRS: base=0.375 kd=0.500 gate=0.375\n",
            " Fold 5/5 | T=0.438 | EEG: base=0.500 kd=0.500 gate=0.500 | fNIRS: base=0.438 kd=0.625 gate=0.625\n",
            "Subject 12 means | T=0.575 | EEG(base/kd/gate)=0.525/0.487/0.525 | fNIRS(base/kd/gate)=0.425/0.512/0.475\n",
            "\n",
            "Subject 13 | trials=80\n",
            " Fold 1/5 | T=0.688 | EEG: base=0.688 kd=0.625 gate=0.688 | fNIRS: base=0.500 kd=0.375 gate=0.500\n",
            " Fold 2/5 | T=0.562 | EEG: base=0.812 kd=0.500 gate=0.812 | fNIRS: base=0.500 kd=0.500 gate=0.500\n",
            " Fold 3/5 | T=0.625 | EEG: base=0.562 kd=0.438 gate=0.562 | fNIRS: base=0.375 kd=0.312 gate=0.375\n",
            " Fold 4/5 | T=0.500 | EEG: base=0.500 kd=0.500 gate=0.500 | fNIRS: base=0.500 kd=0.562 gate=0.500\n",
            " Fold 5/5 | T=0.625 | EEG: base=0.562 kd=0.500 gate=0.562 | fNIRS: base=0.438 kd=0.500 gate=0.438\n",
            "Subject 13 means | T=0.600 | EEG(base/kd/gate)=0.625/0.512/0.625 | fNIRS(base/kd/gate)=0.463/0.450/0.463\n",
            "\n",
            "Subject 15 | trials=80\n",
            " Fold 1/5 | T=0.438 | EEG: base=0.438 kd=0.438 gate=0.438 | fNIRS: base=0.500 kd=0.500 gate=0.500\n",
            " Fold 2/5 | T=0.500 | EEG: base=0.250 kd=0.375 gate=0.250 | fNIRS: base=0.500 kd=0.500 gate=0.500\n",
            " Fold 3/5 | T=0.562 | EEG: base=0.312 kd=0.562 gate=0.312 | fNIRS: base=0.625 kd=0.500 gate=0.625\n",
            " Fold 4/5 | T=0.375 | EEG: base=0.438 kd=0.500 gate=0.438 | fNIRS: base=0.500 kd=0.500 gate=0.500\n",
            " Fold 5/5 | T=0.500 | EEG: base=0.500 kd=0.500 gate=0.500 | fNIRS: base=0.312 kd=0.500 gate=0.312\n",
            "Subject 15 means | T=0.475 | EEG(base/kd/gate)=0.388/0.475/0.388 | fNIRS(base/kd/gate)=0.487/0.500/0.487\n",
            "\n",
            "Subject 16 | trials=80\n",
            " Fold 1/5 | T=0.688 | EEG: base=0.500 kd=0.500 gate=0.500 | fNIRS: base=0.500 kd=0.500 gate=0.500\n",
            " Fold 2/5 | T=0.750 | EEG: base=0.500 kd=0.500 gate=0.500 | fNIRS: base=0.500 kd=0.688 gate=0.688\n",
            " Fold 3/5 | T=0.562 | EEG: base=0.500 kd=0.750 gate=0.750 | fNIRS: base=0.500 kd=0.500 gate=0.500\n",
            " Fold 4/5 | T=0.562 | EEG: base=0.688 kd=0.500 gate=0.688 | fNIRS: base=0.438 kd=0.625 gate=0.625\n",
            " Fold 5/5 | T=0.750 | EEG: base=0.250 kd=0.375 gate=0.250 | fNIRS: base=0.500 kd=0.500 gate=0.500\n",
            "Subject 16 means | T=0.662 | EEG(base/kd/gate)=0.487/0.525/0.537 | fNIRS(base/kd/gate)=0.487/0.562/0.562\n",
            "\n",
            "Subject 17 | trials=80\n",
            " Fold 1/5 | T=0.500 | EEG: base=0.500 kd=0.375 gate=0.375 | fNIRS: base=0.375 kd=0.500 gate=0.375\n",
            " Fold 2/5 | T=0.562 | EEG: base=0.625 kd=0.500 gate=0.625 | fNIRS: base=0.500 kd=0.562 gate=0.562\n",
            " Fold 3/5 | T=0.625 | EEG: base=0.500 kd=0.500 gate=0.500 | fNIRS: base=0.500 kd=0.625 gate=0.625\n",
            " Fold 4/5 | T=0.375 | EEG: base=0.500 kd=0.500 gate=0.500 | fNIRS: base=0.500 kd=0.625 gate=0.625\n",
            " Fold 5/5 | T=0.562 | EEG: base=0.312 kd=0.500 gate=0.312 | fNIRS: base=0.500 kd=0.562 gate=0.562\n",
            "Subject 17 means | T=0.525 | EEG(base/kd/gate)=0.487/0.475/0.463 | fNIRS(base/kd/gate)=0.475/0.575/0.550\n",
            "\n",
            "Subject 18 | trials=80\n",
            " Fold 1/5 | T=0.750 | EEG: base=0.625 kd=0.625 gate=0.625 | fNIRS: base=0.438 kd=0.500 gate=0.438\n",
            " Fold 2/5 | T=0.562 | EEG: base=0.625 kd=0.938 gate=0.938 | fNIRS: base=0.500 kd=0.562 gate=0.562\n",
            " Fold 3/5 | T=0.625 | EEG: base=0.562 kd=0.438 gate=0.562 | fNIRS: base=0.500 kd=0.500 gate=0.500\n",
            " Fold 4/5 | T=0.562 | EEG: base=0.750 kd=0.625 gate=0.750 | fNIRS: base=0.562 kd=0.500 gate=0.562\n",
            " Fold 5/5 | T=0.562 | EEG: base=0.500 kd=0.812 gate=0.812 | fNIRS: base=0.500 kd=0.500 gate=0.500\n",
            "Subject 18 means | T=0.613 | EEG(base/kd/gate)=0.613/0.688/0.738 | fNIRS(base/kd/gate)=0.500/0.512/0.512\n",
            "\n",
            "====================================================================================================\n",
            "FINAL SUMMARY (UPGRADED KD, leakage-free)\n",
            "====================================================================================================\n",
            "Subjects evaluated: 16\n",
            "Teacher Overall mean        = 0.592 ± 0.067\n",
            "EEG-only Baseline mean      = 0.501 ± 0.062\n",
            "EEG-only KD-upgraded mean   = 0.532 ± 0.068\n",
            "EEG-only VAL-gated mean     = 0.527 ± 0.086\n",
            "fNIRS-only Baseline mean    = 0.496 ± 0.053\n",
            "fNIRS-only KD-upgraded mean = 0.515 ± 0.036\n",
            "fNIRS-only VAL-gated mean   = 0.514 ± 0.057\n",
            "(KD warmup=6 epochs, conf_thresh=0.7, VAL gate margin=0.02, gate=True)\n"
          ]
        }
      ]
    }
  ]
}